{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c65c32d",
   "metadata": {},
   "source": [
    "## ë”¥í˜ì´í¬ ë²”ì£„ ëŒ€ì‘ì„ ìœ„í•œ AI íƒì§€ ëª¨ë¸ ê²½ì§„ëŒ€íšŒ\n",
    "\n",
    "**â€»ì£¼ì˜** : ë°˜ë“œì‹œ ë³¸ íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ì œì¶œì„ ìˆ˜í–‰í•´ì•¼ í•˜ë©°, íŒŒì¼ì˜ ì´ë¦„ì€ `task.ipynb`ë¡œ ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a9781",
   "metadata": {},
   "source": [
    "* #### ì¶”ë¡  ì‹¤í–‰ í™˜ê²½\n",
    "    * `python 3.9` í™˜ê²½\n",
    "    * `CUDA 10.2`, `CUDA 11.8`, `CUDA 12.6`ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "    * ê° CUDA í™˜ê²½ì— ë¯¸ë¦¬ ì„¤ì¹˜ë¼ìˆëŠ” torch ë²„ì „ì€ ë‹¤ìŒ í‘œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"center\">Python</th>\n",
    "      <th align=\"center\">CUDA</th>\n",
    "      <th align=\"center\">torch</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"center\" style=\"vertical-align: middle;\">3.8</td>\n",
    "      <td align=\"center\">10.2</td>\n",
    "      <td align=\"center\">1.6.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\" style=\"vertical-align: middle;\">3.9</td>\n",
    "      <td align=\"center\">11.8</td>\n",
    "      <td align=\"center\">1.8.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">3.10</td>\n",
    "      <td align=\"center\">12.6</td>\n",
    "      <td align=\"center\">2.7.1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001744a",
   "metadata": {},
   "source": [
    "#### CUDA ë²„ì „ ê´€ë ¨ ì•ˆë‚´ì‚¬í•­\n",
    "  - ì´ë²ˆ ê²½ì§„ëŒ€íšŒëŠ” 3ê°œì˜ CUDA ë²„ì „ì„ ì§€ì›í•©ë‹ˆë‹¤.  \n",
    "  - ì°¸ê°€ìëŠ” ìì‹ ì˜ ëª¨ë¸ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„±ì— ë§ëŠ” CUDA í™˜ê²½ì„ ì„ íƒí•˜ì—¬ ëª¨ë¸ì„ ì œì¶œí•˜ë©´ ë©ë‹ˆë‹¤.   \n",
    "  - ê° CUDA í™˜ê²½ì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ torchê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë‚˜, ì°¸ê°€ìëŠ” ì œì¶œí•˜ëŠ” CUDA ë²„ì „ê³¼ í˜¸í™˜ë˜ëŠ” torch, í•„ìš”í•œ ë²„ì „ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ `!pip install` í•˜ì—¬ ì‚¬ìš©í•˜ì—¬ë„ ë¬´ê´€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b530b5",
   "metadata": {},
   "source": [
    "* #### `task.ipynb` ì‘ì„± ê·œì¹™\n",
    "ì½”ë“œëŠ” í¬ê²Œ 3ê°€ì§€ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ë©°, í•´ë‹¹ íŒŒíŠ¸ì˜ íŠ¹ì„±ì„ ì§€ì¼œì„œ ë‚´ìš©ì„ í¸ì§‘í•˜ì„¸ìš”.   \n",
    "1. **ì œì¶œìš© aifactory ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì¶”ê°€ í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**\n",
    "    - ì±„ì  ë° ì œì¶œì„ ìœ„í•œ aifactory ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ëŠ” ì…€ì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ ìˆ˜ì •í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "    - ê·¸ ì™¸ë¡œ, ëª¨ë¸ ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§ì ‘ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "2. **ì¶”ë¡ ìš© ì½”ë“œ ì‘ì„±**\n",
    "    - ëª¨ë¸ ë¡œë“œ, ë°ì´í„° ì „ì²˜ë¦¬, ì˜ˆì¸¡ ë“± ì‹¤ì œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“  ì½”ë“œë¥¼ ì´ ì˜ì—­ì— ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "3. **aif.submit() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì œì¶œ**\n",
    "    - **ë§ˆì´ í˜ì´ì§€-í™œë™íˆìŠ¤í† ë¦¬**ì—ì„œ ë°œê¸‰ë°›ì€ key ê°’ì„ í•¨ìˆ˜ì˜ ì¸ìë¡œ ì •í™•íˆ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - **â€»ì£¼ì˜** : ì œì¶œí•˜ê³ ì í•˜ëŠ” CUDA í™˜ê²½ì— ë§ëŠ” keyë¥¼ ì…ë ¥í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"left\">Competition ì´ë¦„</th>\n",
    "      <th align=\"center\">CUDA</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"left\">ë”¥í˜ì´í¬ ë²”ì£„ ëŒ€ì‘ì„ ìœ„í•œ AI íƒì§€ ëª¨ë¸ ê²½ì§„ëŒ€íšŒ</td>\n",
    "      <td align=\"center\">11.8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"left\">ë”¥í˜ì´í¬ ë²”ì£„ ëŒ€ì‘ì„ ìœ„í•œ AI íƒì§€ ëª¨ë¸ ê²½ì§„ëŒ€íšŒ CUDA 12.6</td>\n",
    "      <td align=\"center\">12.6</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"left\">ë”¥í˜ì´í¬ ë²”ì£„ ëŒ€ì‘ì„ ìœ„í•œ AI íƒì§€ ëª¨ë¸ ê²½ì§„ëŒ€íšŒ CUDA 10.2</td>\n",
    "      <td align=\"center\">10.2</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e0843",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e2061",
   "metadata": {},
   "source": [
    "#### 1. ì œì¶œìš© aifactory ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "â€» ê²°ê³¼ ì „ì†¡ì— í•„ìš”í•˜ë¯€ë¡œ ì•„ë˜ì™€ ê°™ì´ aifactory ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë°˜ë“œì‹œ ìµœì‹ ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ë  ìˆ˜ ìˆê²Œë” í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "id": "4acd91eb",
   "metadata": {},
   "source": [
    "!pip install -U aifactory"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d0deb93f",
   "metadata": {},
   "source": [
    "* ìì‹ ì˜ ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ì— í•„ìš”í•œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf6ceb4f",
   "metadata": {},
   "source": [
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install numpy==1.23.5\n",
    "!pip install scipy==1.11.4\n",
    "!pip install scikit-learn==1.3.2\n",
    "!pip install opencv-python-headless==4.9.0.80\n",
    "!pip install pandas==2.0.3\n",
    "!pip install Pillow\n",
    "\n",
    "!pip install insightface\n",
    "!pip install onnxruntime-gpu\n",
    "\n",
    "!pip install efficientnet-pytorch==0.7.1\n",
    "!pip install timm==0.9.12\n",
    "\n",
    "!pip install scikit-image==0.21.0\n",
    "!pip install tqdm==4.65.0\n",
    "!pip install pyyaml==6.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "19999e24",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ad9c94090599941f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eaf1b43e",
   "metadata": {},
   "source": [
    "#### 2. ì¶”ë¡ ìš© ì½”ë“œ ì‘ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d194e",
   "metadata": {},
   "source": [
    "##### ì¶”ë¡  í™˜ê²½ì˜ ê¸°ë³¸ ê²½ë¡œ êµ¬ì¡°\n",
    "\n",
    "- í‰ê°€ ë°ì´í„°ì…‹ ê²½ë¡œ: `./data/`\n",
    "   - ì±„ì ì— ì‚¬ìš©ë  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì€ `./data/` ë””ë ‰í† ë¦¬ ì•ˆì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "   - í•´ë‹¹ ë””ë ‰í† ë¦¬ì—ëŠ” ì´ë¯¸ì§€(JPG, PNG)ì™€ ë™ì˜ìƒ(MP4) íŒŒì¼ì´ ë³„ë„ì˜ í•˜ìœ„ í´ë” ì—†ì´ í˜¼í•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "```bash\n",
    "/aif/\n",
    "â””â”€â”€ data/\n",
    "    â”œâ”€â”€ {ì´ë¯¸ì§€ ë°ì´í„°1}.jpg\n",
    "    â”œâ”€â”€ {ì´ë¯¸ì§€ ë°ì´í„°2}.png\n",
    "    â”œâ”€â”€ {ë™ì˜ìƒ ë°ì´í„°1}.mp4\n",
    "    â”œâ”€â”€ {ì´ë¯¸ì§€ ë°ì´í„°3}.png\n",
    "    â”œâ”€â”€ {ë™ì˜ìƒ ë°ì´í„°2}.mp4\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335719c1",
   "metadata": {},
   "source": [
    "- ëª¨ë¸ ë° ìì› ê²½ë¡œ: ì˜ˆì‹œ : `./model/`\n",
    "   - ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, ì œì¶œëœ ëª¨ë¸ ê´€ë ¨ íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•´ì•¼í•˜ í•˜ëŠ” ìƒëŒ€ ê²½ë¡œì…ë‹ˆë‹¤.\n",
    "   - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜(.pt, .ckpt, .pth ë“±)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1810d",
   "metadata": {},
   "source": [
    "* ì œì¶œ íŒŒì¼ì€ `submission.csv`ë¡œ ì €ì¥ë¼ì•¼ í•©ë‹ˆë‹¤.\n",
    "  * submission.csvëŠ” *filename*ê³¼ *label* ì»¬ëŸ¼ìœ¼ë¡œ êµ¬ì„±ë¼ì•¼ í•©ë‹ˆë‹¤.\n",
    "  * filenameì€ ì¶”ë¡ í•œ íŒŒì¼ì˜ ì´ë¦„(í™•ì¥ì í¬í•¨), labelì€ ì¶”ë¡  ê²°ê³¼ì…ë‹ˆë‹¤. (real:0, fake:1)\n",
    "  * filenameì€ *string*, labelì€ *int* ìë£Œí˜•ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "  * ì¶”ë¡ í•˜ëŠ” ë°ì´í„°ì˜ ìˆœì„œëŠ” ë¬´ì‘ìœ„ë¡œ ì„ì—¬ë„ ìƒê´€ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"center\">filename</th>\n",
    "      <th align=\"center\">label</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"center\">{ì´ë¯¸ì§€ ë°ì´í„°1}.jpg</td>\n",
    "      <td align=\"center\">0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">{ë™ì˜ìƒ ë°ì´í„°1}.mp4</td>\n",
    "      <td align=\"center\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td colspan=\"2\" align=\"center\">...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29c10f",
   "metadata": {},
   "source": [
    "**â€» ì£¼ì˜ ì‚¬í•­**\n",
    "\n",
    "* argparse ì‚¬ìš©ì‹œ `args, _ = parser.parse_known_args()`ë¡œ ì¸ìë¥¼ ì§€ì •í•˜ì„¸ìš”.   \n",
    "   - `args = parser.parse_args()`ëŠ” jupyterì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "* return í•  ê²°ê³¼ë¬¼ê³¼ ì–‘ì‹ì— ìœ ì˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "id": "eff1c36a",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "# insightfaceê°€ ëª¨ë¸ì„ ì°¾ì„ ê²½ë¡œë¥¼ 'insightface_cache' í´ë”ë¡œ ê°•ì œ(ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨ ìš°íšŒ)\n",
    "MODEL_CACHE_DIR = Path(\"./insightface_cache\")\n",
    "os.environ['INSIGHTFACE_HOME'] = str(MODEL_CACHE_DIR.resolve())\n",
    "local_model_root = os.environ.get('INSIGHTFACE_HOME')\n",
    "\n",
    "# ëª¨ë¸ì´ ì œì¶œ í´ë”ì— ì—†ìœ¼ë©´ ì¶”ë¡ ì„ ì¤‘ë‹¨í•˜ê³  ì˜¤ë¥˜ ë°œìƒ\n",
    "# buffalo_l ëª¨ë¸ì˜ í•„ìˆ˜ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "if not (MODEL_CACHE_DIR / \"models/buffalo_l\").exists():\n",
    "    raise FileNotFoundError(f\"InsightFace model 'buffalo_l' not found at {MODEL_CACHE_DIR / 'models/buffalo_l'}. Please check your submission contents.\")\n",
    "\n",
    "print(f\"Set INSIGHTFACE_HOME to: {local_model_root}\")\n",
    "print(\"âœ… Local InsightFace model cache verified.\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "# --- 1. í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸ ---\n",
    "# task.ipynbì™€ ê°™ì€ ìœ„ì¹˜ì— src í´ë” ë°°ì¹˜\n",
    "sys.path.insert(0, \".\")\n",
    "# ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.feature_extraction.feature_extractor import DeepfakeDetectionModel\n",
    "from src.preprocessing.face_detector import create_face_detector\n",
    "from src.preprocessing.face_aligner import FaceAligner\n",
    "\n",
    "print(\"âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "\n",
    "# --- 2. ìƒìˆ˜ ë° ê²½ë¡œ ì„¤ì • ---\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ\n",
    "MODEL_PATH = \"./model/best_model.pth\"\n",
    "# ì„¤ì • íŒŒì¼ ê²½ë¡œ\n",
    "PREPROCESSING_CONFIG = \"./config/preprocessing_config.yaml\"\n",
    "TRAINING_CONFIG = \"./config/model_config.yaml\"\n",
    "\n",
    "# ëŒ€íšŒ í™˜ê²½ ê²½ë¡œ\n",
    "DATA_PATH = Path(\"./data\")\n",
    "OUTPUT_CSV = \"submission.csv\"\n",
    "\n",
    "# ê¸°íƒ€ ì„¤ì •\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "VIDEO_EXTS = {\".mp4\"}\n",
    "FRAME_SAMPLE_COUNT = 5 # ë¹„ë””ì˜¤ë‹¹ ìƒ˜í”Œë§í•  í”„ë ˆì„ ìˆ˜\n",
    "\n",
    "# --- 3. ì„¤ì • íŒŒì¼ ë¡œë“œ ë° í™˜ê²½ ì„¤ì • ---\n",
    "print(f\"Running on device: {DEVICE}\")\n",
    "\n",
    "with open(PREPROCESSING_CONFIG, 'r', encoding='utf-8') as f:\n",
    "    pre_config = yaml.safe_load(f)\n",
    "with open(TRAINING_CONFIG, 'r', encoding='utf-8') as f:\n",
    "    train_config = yaml.safe_load(f)\n",
    "\n",
    "# ì¶”ë¡  í™˜ê²½ì— ë§ê²Œ ì„¤ì • ê°•ì œ\n",
    "pre_config['detection']['device'] = DEVICE.type\n",
    "train_config['hardware']['device'] = DEVICE.type\n",
    "\n",
    "print(\"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# --- 4. ëª¨ë¸ ë° ì „ì²˜ë¦¬ ëª¨ë“ˆ ë¡œë“œ ---\n",
    "\n",
    "# 1) ì „ì²˜ë¦¬ ëª¨ë“ˆ (FaceDetector, FaceAligner)\n",
    "detector = create_face_detector(pre_config['detection'])\n",
    "aligner = FaceAligner(pre_config['alignment'])\n",
    "\n",
    "# 2) ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸ ë¡œë“œ\n",
    "model_cfg = train_config['model']\n",
    "model = DeepfakeDetectionModel(\n",
    "    num_classes=model_cfg['classifier']['num_classes'],\n",
    "    pretrained=False, # í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ë¯€ë¡œ False\n",
    "    feature_extractor_config=model_cfg['feature_extractor'],\n",
    "    classifier_hidden_dims=model_cfg['classifier']['hidden_dims'],\n",
    "    dropout_rate=model_cfg['classifier']['dropout_rate']\n",
    ")\n",
    "\n",
    "# í•™ìŠµëœ ê°€ì¤‘ì¹˜(checkpoint) ë¡œë“œ\n",
    "if not Path(MODEL_PATH).exists():\n",
    "    print(f\"âŒ ì—ëŸ¬: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! {MODEL_PATH}\")\n",
    "else:\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(DEVICE)\n",
    "    model.eval() # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •\n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡  ëª¨ë“œ ì„¤ì • ì™„ë£Œ: {MODEL_PATH}\")\n",
    "\n",
    "# 3) ì´ë¯¸ì§€ ì •ê·œí™” í…ì„œ\n",
    "MEAN_TENSOR = torch.tensor([0.485, 0.456, 0.406], device=DEVICE).view(3, 1, 1)\n",
    "STD_TENSOR = torch.tensor([0.229, 0.224, 0.225], device=DEVICE).view(3, 1, 1)\n",
    "\n",
    "# --- 5. í•µì‹¬ ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ---\n",
    "\n",
    "def preprocess_frame(frame_bgr: np.ndarray) -> Optional[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ í”„ë ˆì„(BGR)ì„ ë°›ì•„ ì „ì²˜ë¦¬í•˜ê³  ëª¨ë¸ ì…ë ¥ í…ì„œ(ì´ë¯¸ì§€, ëœë“œë§ˆí¬)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        detection = detector.detect(frame_rgb)\n",
    "        if detection is None:\n",
    "            return None\n",
    "\n",
    "        aligned_face, tform_matrix = aligner.align(frame_rgb, detection['landmarks'])\n",
    "        aligned_landmarks = aligner.get_aligned_landmarks(\n",
    "            detection['landmarks'],\n",
    "            tform_matrix\n",
    "        )\n",
    "\n",
    "        img_tensor = torch.from_numpy(aligned_face.transpose(2, 0, 1)).float().to(DEVICE)\n",
    "        img_tensor = (img_tensor / 255.0 - MEAN_TENSOR) / STD_TENSOR\n",
    "\n",
    "        lm_tensor = torch.from_numpy(aligned_landmarks).float().to(DEVICE)\n",
    "\n",
    "        return img_tensor, lm_tensor\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def predict_single_file(file_path: Path) -> int:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ íŒŒì¼(ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤) ê²½ë¡œë¥¼ ë°›ì•„ ë”¥í˜ì´í¬ ì—¬ë¶€(0 ë˜ëŠ” 1)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    frame_tensors = []\n",
    "    landmark_tensors = []\n",
    "    ext = file_path.suffix.lower()\n",
    "\n",
    "    try:\n",
    "        if ext in IMAGE_EXTS:\n",
    "            frame = cv2.imread(str(file_path))\n",
    "            if frame is not None:\n",
    "                result = preprocess_frame(frame)\n",
    "                if result:\n",
    "                    frame_tensors.append(result[0])\n",
    "                    landmark_tensors.append(result[1])\n",
    "\n",
    "        elif ext in VIDEO_EXTS:\n",
    "            cap = cv2.VideoCapture(str(file_path))\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "            if total_frames > 0:\n",
    "                frame_indices = np.linspace(0, total_frames - 1, FRAME_SAMPLE_COUNT, dtype=int)\n",
    "\n",
    "                for idx in frame_indices:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret or frame is None:\n",
    "                        continue\n",
    "\n",
    "                    result = preprocess_frame(frame)\n",
    "                    if result:\n",
    "                        frame_tensors.append(result[0])\n",
    "                        landmark_tensors.append(result[1])\n",
    "            cap.release()\n",
    "\n",
    "        # 3. ì˜ˆì¸¡ ì§‘ê³„ (Aggregation)\n",
    "        if not frame_tensors:\n",
    "            return 0 # ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨ ì‹œ Real(0)\n",
    "\n",
    "        images_batch = torch.stack(frame_tensors)\n",
    "        landmarks_batch = torch.stack(landmark_tensors)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(images_batch, landmarks_batch)\n",
    "            probs = F.softmax(logits, dim=1) # (N, 2)\n",
    "\n",
    "        avg_fake_prob = probs[:, 1].mean().item()\n",
    "        final_label = 1 if avg_fake_prob >= 0.5 else 0\n",
    "        return final_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ”¥ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {file_path.name}: {e}\")\n",
    "        return 0 # ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ Real(0)\n",
    "\n",
    "# --- 6. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---\n",
    "print(\"ğŸš€ ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "all_files = [p for p in DATA_PATH.iterdir() if p.is_file() and p.suffix.lower() in (IMAGE_EXTS | VIDEO_EXTS)]\n",
    "results = []\n",
    "\n",
    "for file_path in tqdm(all_files, desc=\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡  ì¤‘\"):\n",
    "    label = predict_single_file(file_path)\n",
    "    results.append({\n",
    "        \"filename\": file_path.name,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "# --- 7. submission.csv íŒŒì¼ ìƒì„± ---\n",
    "if results:\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df['label'] = submission_df['label'].astype(int)\n",
    "    submission_df = submission_df[[\"filename\", \"label\"]]\n",
    "    submission_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"âœ… ì¶”ë¡  ì™„ë£Œ! ê²°ê³¼ê°€ {OUTPUT_CSV} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    # ë¹ˆ submission.csvë¼ë„ ìƒì„±\n",
    "    pd.DataFrame(columns=[\"filename\", \"label\"]).to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"âš ï¸ ì²˜ë¦¬í•  íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìœ¼ë‚˜, ë¹ˆ submission.csvë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"ëª¨ë“  ì¶”ë¡  ê³¼ì •ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6119d40d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f895e41",
   "metadata": {},
   "source": [
    "#### 3. `aif.submit()` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì œì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410d97e",
   "metadata": {},
   "source": [
    "**â€»ì£¼ì˜** : taskë³„, ì°¸ê°€ìë³„ë¡œ keyê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ëª» ì…ë ¥í•˜ì§€ ì•Šë„ë¡ ìœ ì˜ë°”ëë‹ˆë‹¤.\n",
    "- keyëŠ” ëŒ€íšŒ í˜ì´ì§€ [ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œ](https://aifactory.space/task/9197/baseline) íƒ­ì— ê¸°ì¬ëœ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ task ë³„ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- keyê°€ í‹€ë¦¬ë©´ ì œì¶œì´ ì§„í–‰ë˜ì§€ ì•Šê±°ë‚˜ ì˜ëª» ì œì¶œë˜ë¯€ë¡œ taskì— ë§ëŠ” ìì‹ ì˜ keyë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "-  **NOTE** : ì´ë²ˆ ê²½ì§„ëŒ€íšŒì—ì„œëŠ” 3ê°œì˜ CUDA ë²„ì „ì„ ì§€ì›í•˜ë©°, ê° CUDA ë²„ì „ì— ë”°ë¼ task keyê°€ ìƒì´í•©ë‹ˆë‹¤. í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— í˜„ì¬ keyê°€ ì œì¶œí•˜ê³ ì í•˜ëŠ” CUDA í™˜ê²½ì— ëŒ€í•œ keyì¸ì§€ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "id": "d4df34c8",
   "metadata": {},
   "source": [
    "import aifactory.score as aif\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "aif.submit(model_name=\"faker\",\n",
    "    key=\"eb78b4fd-975e-496c-9dbe-acbc76123fb2\"\n",
    ")\n",
    "#-----------------------------------------------------#\n",
    "print(time.time() - t)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "290ac2b2",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c91c789ce2d9a88b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
